<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="TARGET Benchmark for Evaluating Table Retrieval in RAG Pipelines">
  <meta property="og:title" content="TARGET Benchmark"/>
  <meta property="og:description" content="TARGET Benchmark for Evaluating Table Retrieval in RAG Pipelines"/>
  <meta property="og:url" content="https://target-benchmark.github.io"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/images/target_img.png" />
  <meta property="og:image:width" content="630"/>
  <meta property="og:image:height" content="630"/>


  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="table retrieval, benchmark, RAG, QA, text-to-sql">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>TARGET: Benchmarking Table Retrieval for Generative Tasks</title>
  <link rel="icon" type="image/x-icon" href="static/images/target_img.png">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">&#127919; TARGET: Benchmarking Table Retrieval for Generative Tasks</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">Xingyu Ji,</span>
                <span class="author-block"> <a href="https://people.eecs.berkeley.edu/~adityagp/" target="_blank">Aditya Parameswaran</a>,</span>
              <span class="author-block"> <a href="https://www.madelonhulsebos.com" target="_blank">Madelon Hulsebos</a><sup>*</sup></span>
              </div>

            <div class="is-size-5 publication-authors">
                <span class="author-block">UC Berkeley</span>
                <span class="eql-cntrb"><small><br><sup>*</sup>Now at CWI</small></span>
               </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="/static/pdfs/TARGET_TRL_NeurIPS.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <span class="link-block">
                      <a href="https://huggingface.co/target-benchmark" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        &#129303;
                      </span>
                      <span>HuggingFace</span>
                    </a>
                  </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/target-benchmark/target" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
<!--                 <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                <span>arXiv</span> -->
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="static/images/target_diagram.jpg" alt="Overview diagram of the TARGET benchmark for evaluating table retrieval for generative tasks"/>
<!--       <video poster="" id="tree" autoplay controls muted loop height="100%"> -->
        <!-- Your video here -->
<!--         <source src="static/videos/banner_video.mp4"
        type="video/mp4"> -->
<!--       </video> -->
      <h2 class="subtitle has-text-centered">
       Overview of the TARGET benchmark.
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
         The data landscape is rich with structured data, often of high value to organizations, that drive important applications in data analysis and machine learning.
Recent progress in representation learning and generative models for such data has led to the development of natural language interfaces to structured data, including those that leverage text-to-SQL.
            Contextualizing interactions, including conversational and agentic elements, in structured data through retrieval-augmented
generation can provide substantial benefits in the form of freshness, accuracy, and
comprehensiveness of answers. The key question, however, is: how do we retrieve the right table(s) for the analytical query or task at hand? To investigate this
question, we introduce <b>TARGET</b>: a benchmark for evaluating <b>TA</b>ble <b>R</b>etrieval for
<b>GE</b>nerative <b>T</b>asks. We use TARGET to analyze the retrieval performance of dif
ferent retrievers in isolation, as well as their impact on downstream generators for
question answering, fact verification, and text-to-SQL. We find that out-of-the-box
embedding-based retrievers far outperform a BM25 baseline which appears less
effective than it is for retrieval over unstructured text. We also surface the sensitiv
ity of retrievers across various metadata (e.g., missing table titles), and illustrate a
stark variation of retrieval performance across datasets and tasks. TARGET is developed for easy reuse and extension to advance research on retrieval methods and
pipelines for relational data through fine-grained, comprehensive, and consistent
evaluation.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<section>
  <div class="container is-max-desktop">
    <div class="hero-body">
      <h2 class="title">Key findings (initial)</h2>

      <img src="static/images/target_results.png" alt="Main results of the TARGET benchmark for various retrievers, tasks and datasets"/><br>

      <b>Retrieval</b><br>
    We find that lexical methods based on BM25 and TF-IDF are less effective than they are for text, even with increased k. The high performance of these methods on the OTTQA dataset appears to be mainly driven by the high correspondence between Wikipedia table title and queries, as the performance drops when
    the title is left out (Table 2). We observe a similar pattern for these methods on the text-to-SQL tasks when table names are not included, which is further confirmed with results on FeTaQA, where the table titles are not descriptive and including them does not enhance performance. These findings emphasize the potential critical role of table metadata. Embeddings of table headers and rows generally yield the best performance. LLM-generated table summaries with LlamaIndex results in lower retrieval performance and
    efficiency than the direct table embedding pipeline, but generating descriptive table titles in place of non-descriptive ones (e.g., FeTaQA) can enhance retrieval performance. For both text-to-SQL datasets, including data rows in the embedding actually lowers retrieval performance.<br>
    <br>
    <b>Generation</b><br>
    Unsurprisingly, we observe that providing database schemas for text-to-SQL is critical to generate accurate SQL queries, as the No Context baseline yields an accuracy of 0.
    The low performance of all retrievers on the OTTQA dataset is also notable, which we hypothesize is due to the relatively short answers in OTTQA versus longer generated answers despite prompting for
    conciseness. Overall, we find that dense embeddings yield better retrieval performance. Notably, for the fact verification task, the precision and recall with OpenAI embeddings are significantly
    higher than when evaluating the statements without context, i.e., using only the memory of the LLM, underlining the value of grounding LLMs conversations in factual structured data. When we
    exclude all “not enough information” responses, we find that the recall across all retrievers increases to approximately 0.747, which confirms the impact of incorporating relevant tables into the context.
  </div>
</section>


<section>
  <div class="container is-max-desktop">
    <div class="hero-body">
      <h2 class="title">Contact</h2>
      We warmly welcome contributions and suggestions for TARGET, please find instructions at: <a href="https://github.com/target-benchmark/target">https://github.com/target-benchmark/target</a>.
      Want to share/discuss something else, please reach out to Madelon Hulsebos (<a href="mailto:madelon@cwi.nl">madelon@cwi.nl</a>)!
  </div>
</section>



<!--BibTex citation -->
<section class="section" id="BibTex">
    <div class="container is-max-desktop content">
      <h2 class="title">Citation</h2>
        <pre><code>@inproceedings{ji2024target,
  title={TARGET: Benchmarking Table Retrieval for Generative Tasks},
  author={Ji, Xingyu and Parameswaran, Aditya and Hulsebos, Madelon},
  booktitle={NeurIPS 2024 Third Table Representation Learning Workshop}
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
